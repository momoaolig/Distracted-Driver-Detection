{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T02:27:43.208838200Z",
     "start_time": "2024-04-17T02:27:41.863734600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# print('CPU:', tf.config.list_physical_devices(device_type='CPU'))\n",
    "# print('GPU:', tf.config.list_physical_devices(device_type='GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  subject classname            img\n0    p002        c0  img_44733.jpg\n1    p002        c0  img_72999.jpg\n2    p002        c0  img_25094.jpg\n3    p002        c0  img_69092.jpg\n4    p002        c0  img_92629.jpg",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>classname</th>\n      <th>img</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>p002</td>\n      <td>c0</td>\n      <td>img_44733.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>p002</td>\n      <td>c0</td>\n      <td>img_72999.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>p002</td>\n      <td>c0</td>\n      <td>img_25094.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>p002</td>\n      <td>c0</td>\n      <td>img_69092.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>p002</td>\n      <td>c0</td>\n      <td>img_92629.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './sfddd/driver_imgs_list.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T02:11:33.890526600Z",
     "start_time": "2024-04-17T02:11:33.835926600Z"
    }
   },
   "id": "a06198fae9bca300",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224,224)\n",
    "# num: how many images in sequence do you want to load\n",
    "def load_train_data(num):\n",
    "    images = []\n",
    "    labels = []\n",
    "    dataset = './sfddd/imgs/train'\n",
    "    for folder in os.listdir(dataset):\n",
    "        label = folder\n",
    "        subdir = f'{dataset}/{folder}'\n",
    "        for file in tqdm(os.listdir(subdir)[:num]):\n",
    "            img_path = os.path.join(subdir, file)\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, IMAGE_SIZE) # to match ResNet\n",
    "            images.append(image)\n",
    "            labels.append(int(label[-1]))\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return [images, labels]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T02:21:44.661972200Z",
     "start_time": "2024-04-17T02:21:44.655966800Z"
    }
   },
   "id": "a515893cd1a68407",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 427.48it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 420.89it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 414.65it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 356.41it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 429.08it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 439.44it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 417.82it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 424.12it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 430.90it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 316.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000\n",
      "(1000, 224, 224, 3) (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_train_data(100)\n",
    "y = to_categorical(y)\n",
    "print(len(X), len(y))\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T02:27:49.302285100Z",
     "start_time": "2024-04-17T02:27:46.680633100Z"
    }
   },
   "id": "956552c065176b6f",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 4s/step - accuracy: 0.0764 - loss: 146.0005 - val_accuracy: 0.0900 - val_loss: 251.2826\n",
      "Epoch 2/10\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 3s/step - accuracy: 0.1857 - loss: 196.1806 - val_accuracy: 0.2654 - val_loss: 56.1180\n",
      "Epoch 3/10\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 3s/step - accuracy: 0.2491 - loss: 52.8528 - val_accuracy: 0.2701 - val_loss: 25.1765\n",
      "Epoch 4/10\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 3s/step - accuracy: 0.4235 - loss: 16.1276 - val_accuracy: 0.2844 - val_loss: 9.3138\n",
      "Epoch 5/10\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 3s/step - accuracy: 0.5050 - loss: 4.0995 - val_accuracy: 0.5024 - val_loss: 4.5791\n",
      "Epoch 6/10\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 3s/step - accuracy: 0.7197 - loss: 1.9465 - val_accuracy: 0.6303 - val_loss: 2.6717\n",
      "Epoch 7/10\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 3s/step - accuracy: 0.8709 - loss: 0.6108 - val_accuracy: 0.6730 - val_loss: 1.6873\n",
      "Epoch 8/10\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 3s/step - accuracy: 0.9507 - loss: 0.1610 - val_accuracy: 0.7346 - val_loss: 1.1575\n",
      "Epoch 9/10\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 3s/step - accuracy: 0.9826 - loss: 0.0657 - val_accuracy: 0.7156 - val_loss: 1.2444\n",
      "Epoch 10/10\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 3s/step - accuracy: 0.9958 - loss: 0.0324 - val_accuracy: 0.7678 - val_loss: 1.1887\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x134e7d36300>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet\n",
    "model = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "x = Flatten()(model.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "model = Model(inputs=model.input, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=100, validation_split=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T02:32:54.973294700Z",
     "start_time": "2024-04-17T02:30:11.117782300Z"
    }
   },
   "id": "8ce0df988eff4a81",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 579ms/step - accuracy: 0.8138 - loss: 0.8855\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.0393413305282593, 0.79666668176651]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T02:35:04.552400900Z",
     "start_time": "2024-04-17T02:34:58.410683300Z"
    }
   },
   "id": "4605bf87c170e326",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dd7fc037b9d4b3a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
